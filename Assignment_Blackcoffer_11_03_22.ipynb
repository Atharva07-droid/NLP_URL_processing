{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c51529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import openpyxl\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "import syllables\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5b81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44e0fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2468dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url_id, url in zip(df['URL_ID'], df['URL']):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    div_tag = soup.find('div', class_='td-post-content')\n",
    "\n",
    "    if div_tag != None:\n",
    "        data1 = div_tag.find_all(text=True)\n",
    "        data = ''\n",
    "        data = soup.find('title').text[:-23]\n",
    "        \n",
    "        for text in data1:\n",
    "            data += (text)\n",
    "            \n",
    "        f = open(str(url_id)+\".txt\", \"w+\", encoding=\"utf-8\")\n",
    "        n = f.write(data)\n",
    "        f.close()\n",
    "        \n",
    "    else:\n",
    "        f = open(str(url_id)+\".txt\", \"w+\", encoding=\"utf-8\")\n",
    "        n = f.write(\"\")\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c46ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'StopWords'\n",
    "word_list = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            text = f.read()\n",
    "            \n",
    "        words = text.split()\n",
    "        word_list.extend(words)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c1ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     URL_ID                                                URL  \\\n",
      "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
      "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
      "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
      "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
      "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
      "..      ...                                                ...   \n",
      "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
      "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
      "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
      "112     149  https://insights.blackcoffer.com/business-anal...   \n",
      "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
      "\n",
      "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
      "0               NaN             NaN             NaN                 NaN   \n",
      "1               NaN             NaN             NaN                 NaN   \n",
      "2               NaN             NaN             NaN                 NaN   \n",
      "3               NaN             NaN             NaN                 NaN   \n",
      "4               NaN             NaN             NaN                 NaN   \n",
      "..              ...             ...             ...                 ...   \n",
      "109             NaN             NaN             NaN                 NaN   \n",
      "110             NaN             NaN             NaN                 NaN   \n",
      "111             NaN             NaN             NaN                 NaN   \n",
      "112             NaN             NaN             NaN                 NaN   \n",
      "113             NaN             NaN             NaN                 NaN   \n",
      "\n",
      "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
      "0                    NaN                          NaN        NaN   \n",
      "1                    NaN                          NaN        NaN   \n",
      "2                    NaN                          NaN        NaN   \n",
      "3                    NaN                          NaN        NaN   \n",
      "4                    NaN                          NaN        NaN   \n",
      "..                   ...                          ...        ...   \n",
      "109                  NaN                          NaN        NaN   \n",
      "110                  NaN                          NaN        NaN   \n",
      "111                  NaN                          NaN        NaN   \n",
      "112                  NaN                          NaN        NaN   \n",
      "113                  NaN                          NaN        NaN   \n",
      "\n",
      "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
      "0                                 NaN                 NaN         NaN   \n",
      "1                                 NaN                 NaN         NaN   \n",
      "2                                 NaN                 NaN         NaN   \n",
      "3                                 NaN                 NaN         NaN   \n",
      "4                                 NaN                 NaN         NaN   \n",
      "..                                ...                 ...         ...   \n",
      "109                               NaN                 NaN         NaN   \n",
      "110                               NaN                 NaN         NaN   \n",
      "111                               NaN                 NaN         NaN   \n",
      "112                               NaN                 NaN         NaN   \n",
      "113                               NaN                 NaN         NaN   \n",
      "\n",
      "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
      "0                  NaN                NaN              NaN  \n",
      "1                  NaN                NaN              NaN  \n",
      "2                  NaN                NaN              NaN  \n",
      "3                  NaN                NaN              NaN  \n",
      "4                  NaN                NaN              NaN  \n",
      "..                 ...                ...              ...  \n",
      "109                NaN                NaN              NaN  \n",
      "110                NaN                NaN              NaN  \n",
      "111                NaN                NaN              NaN  \n",
      "112                NaN                NaN              NaN  \n",
      "113                NaN                NaN              NaN  \n",
      "\n",
      "[114 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df_output = pd.read_csv('Output Data Structure.csv')\n",
    "print(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d987fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "# folder_path = 'StopWords'\n",
    "# word_list = []\n",
    "\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "#     if os.path.isfile(file_path):\n",
    "#         with open(file_path, 'r') as f:\n",
    "#             text = f.read()\n",
    "            \n",
    "#         words = text.split()\n",
    "#         word_list.extend(words)\n",
    "# f.close()\n",
    "\n",
    "# print(word_list)\n",
    "\n",
    "positive_words = []\n",
    "\n",
    "with open(r\"C:\\Users\\athar\\Programming\\Jupyter\\Blackcoffer\\MasterDictionary\\positive-words.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "f.close()\n",
    "positive = text.split()\n",
    "positive_words.extend(positive)\n",
    "\n",
    "# print(positive_words)\n",
    "\n",
    "negative_words = []\n",
    "\n",
    "with open(r\"C:\\Users\\athar\\Programming\\Jupyter\\Blackcoffer\\MasterDictionary\\negative-words.txt\", 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "f.close()\n",
    "negative = text.split()\n",
    "negative_words.extend(negative)\n",
    "\n",
    "# print(negative_words)\n",
    "\n",
    "for url_id, url in zip(df_output['URL_ID'], df_output['URL']):\n",
    "    with open(str(url_id)+\".txt\", 'r+', encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    words = nltk.word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in word_list]\n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    for words in filtered_words:\n",
    "        if words in positive_words:\n",
    "            positive_score += 1\n",
    "        elif words in negative_words:\n",
    "            negative_score += -1\n",
    "        \n",
    "    negative_score *= -1\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence) \n",
    "        filtered_words = [word for word in words if word.lower() not in word_list] \n",
    "        cleaned_sentence = ' '.join(filtered_words)\n",
    "        cleaned_sentences.append(cleaned_sentence)\n",
    "    cleaned_sentences = ' '.join(cleaned_sentences)\n",
    "#     print(cleaned_sentences)\n",
    "\n",
    "#     print(positive_score)\n",
    "#     print(negative_score)\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "#     print(polarity_score)\n",
    "    \n",
    "    no_punct = cleaned_sentences.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "#     print(no_punct)\n",
    "\n",
    "    words = no_punct.split()\n",
    "    num_words = len(words)\n",
    "#     print(num_words)\n",
    "\n",
    "    subjectivity_score = (positive_score + negative_score) / (num_words + 0.000001)\n",
    "#     print(subjectivity_score)\n",
    "\n",
    "    sentences = nltk.sent_tokenize(cleaned_sentences)\n",
    "    num_sentences = len(sentences)\n",
    "#     print(num_sentences)\n",
    "    \n",
    "    if num_sentences > 0 and num_words > 0:\n",
    "        Average_Sentence_Length = num_words / num_sentences\n",
    "    #     print(Average_Sentence_Length)\n",
    "    else:\n",
    "        Average_Sentence_Length = 0\n",
    "    \n",
    "    threshold = 3\n",
    "    words = cleaned_sentences.split()\n",
    "    num_complex_words = 0\n",
    "\n",
    "    for word in words:\n",
    "        syllable_count = syllables.estimate(word)\n",
    "        if syllable_count >= threshold:\n",
    "            num_complex_words += 1\n",
    "\n",
    "#     print(num_complex_words\n",
    "\n",
    "    if num_complex_words > 0 and num_words > 0:\n",
    "        Percentage_Complex_words = num_complex_words / num_words\n",
    "    #     print(Percentage_Complex_words)\n",
    "    else:\n",
    "        Percentage_Complex_words = 0\n",
    "\n",
    "    Fog_index = 0.4 * (Average_Sentence_Length + Percentage_Complex_words)\n",
    "#     print(Fog_index)\n",
    "\n",
    "    pronoun_count = re.compile(r'\\b(I|we|ours|my|mine|(?-i:us))\\b', re.I)\n",
    "    pronouns = pronoun_count.findall(cleaned_sentences)\n",
    "#     print(len(pronouns))\n",
    "\n",
    "    words = nltk.word_tokenize(no_punct)\n",
    "    \n",
    "    total_length = sum(len(word) for word in words)\n",
    "\n",
    "    if total_length > 0 and len(words) > 0:\n",
    "        average_word_length = total_length / len(words)\n",
    "    else:\n",
    "        average_word_length = 0\n",
    "\n",
    "#     print(average_word_length)\n",
    "    df_output.loc[i,['POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH'\n",
    "        , 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT'\n",
    "        ,'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']] = [positive_score, negative_score\n",
    "    , polarity_score, subjectivity_score, Average_Sentence_Length, Percentage_Complex_words, Fog_index, Average_Sentence_Length\n",
    "    , num_complex_words, num_words, syllable_count, len(pronouns), average_word_length]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b696267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     URL_ID                                                URL  \\\n",
      "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
      "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
      "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
      "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
      "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
      "..      ...                                                ...   \n",
      "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
      "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
      "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
      "112     149  https://insights.blackcoffer.com/business-anal...   \n",
      "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
      "\n",
      "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
      "0              63.0            33.0        0.312500            0.091516   \n",
      "1              56.0            38.0        0.191489            0.146646   \n",
      "2              66.0            35.0        0.306931            0.113356   \n",
      "3              57.0            25.0        0.390244            0.111111   \n",
      "4              50.0            24.0        0.351351            0.084960   \n",
      "..              ...             ...             ...                 ...   \n",
      "109            22.0            28.0       -0.120000            0.104603   \n",
      "110            41.0            12.0        0.547170            0.061628   \n",
      "111            26.0            44.0       -0.257143            0.110585   \n",
      "112            31.0             4.0        0.771429            0.090206   \n",
      "113            32.0            39.0       -0.098592            0.136276   \n",
      "\n",
      "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
      "0              13.278481                     0.486177   5.505863   \n",
      "1               7.913580                     0.377535   3.316446   \n",
      "2              10.360465                     0.508418   4.347553   \n",
      "3               7.768421                     0.380759   3.259672   \n",
      "4              10.247059                     0.414466   4.264610   \n",
      "..                   ...                          ...        ...   \n",
      "109             9.755102                     0.428870   4.073589   \n",
      "110            14.333333                     0.394186   5.891008   \n",
      "111             9.590909                     0.447077   4.015195   \n",
      "112            13.379310                     0.579897   5.583683   \n",
      "113             7.893939                     0.464491   3.343372   \n",
      "\n",
      "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
      "0                           13.278481               510.0      1049.0   \n",
      "1                            7.913580               242.0       641.0   \n",
      "2                           10.360465               453.0       891.0   \n",
      "3                            7.768421               281.0       738.0   \n",
      "4                           10.247059               361.0       871.0   \n",
      "..                                ...                 ...         ...   \n",
      "109                          9.755102               205.0       478.0   \n",
      "110                         14.333333               339.0       860.0   \n",
      "111                          9.590909               283.0       633.0   \n",
      "112                         13.379310               225.0       388.0   \n",
      "113                          7.893939               242.0       521.0   \n",
      "\n",
      "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
      "0                  5.0                0.0         7.348904  \n",
      "1                  1.0                1.0         6.619345  \n",
      "2                  1.0                0.0         7.415264  \n",
      "3                  3.0                0.0         6.620596  \n",
      "4                  4.0                0.0         6.857635  \n",
      "..                 ...                ...              ...  \n",
      "109                4.0                0.0         7.347280  \n",
      "110                2.0                0.0         6.772093  \n",
      "111                3.0                0.0         6.810427  \n",
      "112                4.0                0.0         7.837629  \n",
      "113                1.0                0.0         7.069098  \n",
      "\n",
      "[114 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bfef88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375807d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
